{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4xTmQKkrGR"
      },
      "source": [
        "# Language Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25b1VTmVkrGT"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/inner-LMNt/Self-GPT.git\n",
        "%cd Self-GPT\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8efwRtXEkrGU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "from models.LLM.config import Config\n",
        "from models.LLM.GPT import GPT\n",
        "from models.LLM.bigram import BigramLanguageModel, BigramNoAttention\n",
        "from models.LLM.trigram import TrigramLanguageModel, TrigramNoAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IjWv-4WkrGV"
      },
      "outputs": [],
      "source": [
        "def load_json(file):\n",
        "    with open(file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def n_gram(number=2):\n",
        "    config = Config()\n",
        "    # torch.manual_seed(config.seed)\n",
        "\n",
        "    model_name = \"shakespeare_model\"\n",
        "\n",
        "    if number == 2:\n",
        "        path = config.checkpoint_dir + f\"/bigram/{model_name}.pth\"\n",
        "        LLM = BigramLanguageModel().to(config.device)\n",
        "    else:\n",
        "        path = config.checkpoint_dir + f\"/trigram/{model_name}.pth\"\n",
        "        LLM = TrigramLanguageModel().to(config.device)\n",
        "\n",
        "    try:\n",
        "        LLM.load_state_dict(torch.load(path, map_location=config.device))\n",
        "        print(\"Model loaded successfully:\", path)\n",
        "        print(\"Training...\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"Training model from scratch...\")\n",
        "\n",
        "    data = load_json(config.data_dir + '/' + config.data_file)\n",
        "    data = torch.tensor(data, dtype=torch.long)\n",
        "\n",
        "    split = int(0.9 * len(data))\n",
        "    train_data, val_data = data[:split], data[split:]\n",
        "\n",
        "    def generate_batch(train):\n",
        "        data = train_data if train else val_data\n",
        "        offsets = torch.randint(len(data) - config.context_len, (config.batch_size,))\n",
        "        inputs = torch.stack([data[i:i+config.context_len] for i in offsets])\n",
        "        targets = torch.stack([data[i+1:i+config.context_len+1] for i in offsets])\n",
        "        return inputs.to(config.device), targets.to(config.device)\n",
        "\n",
        "    start = time.time()\n",
        "    optimizer = torch.optim.Adam(LLM.parameters(), lr=config.learning_rate)\n",
        "    for _ in range(10000):\n",
        "        x, y = generate_batch(True)\n",
        "        logits, loss = LLM.forward(x, y)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward() # Gradients\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "    print(\"\\n______________________________________________________\")\n",
        "    print(f\"Training loss: {loss.item()}, Validation loss: {LLM.forward(*generate_batch(False))[1].item()}\")\n",
        "    print(f\"Training time: {time.time() - start} seconds\")\n",
        "    print(\"______________________________________________________\\n\")\n",
        "\n",
        "    print(f\"Saving model to {path}\")\n",
        "    try:\n",
        "        torch.save(LLM.state_dict(), path)\n",
        "        print(\"Model saved successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyo_7Z1kkrGV"
      },
      "source": [
        "## Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVUUsLt9krGX"
      },
      "outputs": [],
      "source": [
        "n_gram(2) # or 3\n",
        "print(\"\\nFinished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cARXX-SVkrGX"
      },
      "source": [
        "## Download Trained Model\n",
        "\n",
        "After training, you can download the model using the code or just right-\n",
        "clicking the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEi14tSikrGX"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "config = Config()\n",
        "model_type = \"bigram\"\n",
        "model_name = \"shakespeare_model\"\n",
        "\n",
        "# Adjust the path based on which model you trained\n",
        "path = config.checkpoint_dir + f\"/{model_type}/{model_name}.pth\"\n",
        "\n",
        "if os.path.exists(path):\n",
        "    files.download(path)\n",
        "else:\n",
        "    print(f\"Model file not found at {path}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}